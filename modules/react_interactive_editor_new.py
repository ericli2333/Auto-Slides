#!/usr/bin/env python3
"""
React Interactive Editor - Rewritten Version
Based on intelligent semantic positioning, not dependent on page numbering system
"""

import json
import re
import subprocess
import os
import webbrowser
import openai
from difflib import unified_diff
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configure OpenAI client
client = openai.OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url=os.getenv("OPENAI_API_BASE")
)

# Import prompts
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from prompts.react_editor_prompts import (
    DOCUMENT_STRUCTURE_ANALYSIS_PROMPT,
    CODE_LOCATION_PROMPT,
    CODE_MODIFICATION_PROMPT,
    REACT_DECISION_PROMPT,
    create_content_insertion_prompt,
    LATEX_EXPERT_SYSTEM_PROMPT,
    USER_CONFIRMATION_PROMPTS,
    REFERENCE_SEARCH_ENHANCEMENT
)

class ReactInteractiveEditor:
    """
    Intelligent LaTeX editor using ReAct mode for interactive modifications
    Based on document semantic understanding rather than page numbering for positioning
    """
    
    def __init__(self, tex_file_path, source_content=None, workflow_state=None, model_name="gpt-4o"):
        """
        Initialize editor
        
        Args:
            tex_file_path: LaTeX file path
            source_content: Original PDF parsing content (optional, for content expansion)
            workflow_state: Workflow state manager, for accessing intermediate products
            model_name: Language model name to use (default: "gpt-4o")
        """
        self.tex_file_path = tex_file_path
        self.source_content = source_content
        self.workflow_state = workflow_state
        self.model_name = model_name
        self.conversation_history = []
        
        # Initialize reference retrieval agent (if workflow state is available)
        self.reference_agent = None
        if workflow_state and workflow_state.is_ready_for_reference_search():
            try:
                # Fix import path - use modules.reference_agent path
                from modules.reference_agent.reference_agent import ReferenceAgent
                self.reference_agent = ReferenceAgent()
                print("   ‚úÖ Reference search agent initialized")
            except ImportError as e:
                try:
                    # Backup import path
                    import sys
                    import os
                    sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
                    from modules.reference_agent.reference_agent import ReferenceAgent
                    self.reference_agent = ReferenceAgent()
                    print("   ‚úÖ Reference search agent initialized (backup path)")
                except Exception as e2:
                    print(f"   ‚ö†Ô∏è Reference search agent initialization failed: {e2}")
                    self.reference_agent = None
            except Exception as e:
                print(f"   ‚ö†Ô∏è Reference search agent initialization failed: {e}")
                self.reference_agent = None
        
        # Read document content
        with open(tex_file_path, 'r', encoding='utf-8') as f:
            self.document_content = f.read()
        
        # Generate document structure map
        print("   Generating document structure map...")
        self.document_map = self._build_document_map()
        
        print(f"‚úì Document loaded and preprocessed: {self.tex_file_path}")
        print(f"  Document size: {len(self.document_content)} characters")
        if source_content:
            print(f"  Original PDF content provided, content expansion feature enabled")
        print()
    
    def _build_document_map(self):
        """
        Build structured map of document to help LLM understand document structure
        
        Returns:
            dict: Document map containing slides list, or None if generation fails
        """
        try:
            system_prompt = DOCUMENT_STRUCTURE_ANALYSIS_PROMPT
            
            prompt = f"Please analyze the following LaTeX document and generate a structured map:\n```latex\n{self.document_content}\n```"
            
            result_json = self._call_llm([{"role": "user", "content": prompt}], system_prompt, json_mode=True)
            
            if result_json and "slides" in result_json:
                print(f"   ‚úì Document map generated: {result_json['total_slides']} slides")
                return result_json
            else:
                print("   ‚ö†Ô∏è Document map generation failed, will use backup positioning method")
                return None
                
        except Exception as e:
            print(f"   ‚ùå Document map generation error: {e}")
            return None
    
    def _call_llm(self, messages, system_prompt, temperature=0.1, json_mode=False):
        """
        General LLM calling function
        
        Args:
            messages: Message list
            system_prompt: System prompt
            temperature: Temperature parameter
            json_mode: Whether to use JSON mode
            
        Returns:
            dict|str: LLM response result
        """
        try:
            full_messages = [{"role": "system", "content": system_prompt}] + messages
            response_format = {"type": "json_object"} if json_mode else {"type": "text"}
            
            response = client.chat.completions.create(
                model=self.model_name,
                messages=full_messages,
                temperature=temperature,
                response_format=response_format
            )
            content = response.choices[0].message.content
            return json.loads(content) if json_mode else content
        except Exception as e:
            print(f"‚ùå LLM call failed: {e}")
            return None
    
    def locate_code_snippet(self, description):
        """
        Intelligently locate code snippets, supports multi-target positioning
        
        Args:
            description: User description
            
        Returns:
            dict: {
                "snippets": [{"slide_number": int, "code": str, "description": str}],
                "analysis": "Analysis result"
            }
        """
        print(f"ReAct Agent [Locating]... {description}")
        
        system_prompt = CODE_LOCATION_PROMPT
        
        # Build complete context including document map
        context_parts = []
        
        if self.document_map:
            map_summary = f"Document Map ({self.document_map['total_slides']} slides total):\n"
            for slide in self.document_map['slides']:
                map_summary += f"Page {slide['slide_number']}: {slide['type']} - {slide.get('title', 'N/A')}"
                if slide.get('section'):
                    map_summary += f" (Section: {slide['section']})"
                if slide.get('has_image'):
                    map_summary += f" [Images: {', '.join(slide.get('image_files', []))}]"
                if slide.get('has_table'):
                    map_summary += " [Contains Table]"
                map_summary += f"\n  Summary: {slide.get('content_summary', 'None')}\n"
            context_parts.append(map_summary)
        else:
            context_parts.append("‚ö†Ô∏è Document map unavailable, will analyze based on source code directly")
        
        context_parts.append(f"LaTeX Source Code:\n```latex\n{self.document_content}\n```")
        full_context = "\n\n".join(context_parts)
        
        prompt = f"{full_context}\n\nUser Request: {description}"
        
        result_json = self._call_llm([{"role": "user", "content": prompt}], system_prompt, json_mode=True)
        
        if result_json and result_json.get("snippets"):
            snippets = result_json.get("snippets", [])
            analysis = result_json.get("analysis", "")
            
            print(f"   ‚úì Found {len(snippets)} code snippets")
            if analysis:
                print(f"   üìã Analysis: {analysis}")
            
            for i, snippet_info in enumerate(snippets, 1):
                slide_num = snippet_info.get("slide_number", "Unknown")
                desc = snippet_info.get("description", "")
                code = snippet_info.get("code", "")
                print(f"   {i}. Page {slide_num}: {desc} ({len(code)} characters)")
            
            return result_json
        else:
            print("   ‚ùå Failed to locate relevant code")
            return {"snippets": [], "analysis": "No matching code snippets found"}
    
    def generate_modified_code(self, original_snippet, instruction, full_document_context):
        """
        Generate modified code according to instructions
        
        Args:
            original_snippet: Original code snippet
            instruction: Modification instruction
            full_document_context: Complete document context
            
        Returns:
            str: Modified code, or None if failed
        """
        print(f"ReAct Agent [Modifying]... {instruction}")
        
        system_prompt = CODE_MODIFICATION_PROMPT
        
        # Build complete context including original PDF content
        context_parts = [f"Complete LaTeX document content:\n```latex\n{full_document_context}\n```"]
        
        if self.source_content:
            context_parts.append(f"Original PDF parsing content (for enhancement features):\n```json\n{json.dumps(self.source_content, ensure_ascii=False, indent=2)}\n```")
        
        full_context = "\n\n".join(context_parts)
        
        prompt = f"{full_context}\n\nCode snippet to modify:\n```latex\n{original_snippet}\n```\n\nPlease modify it according to the following instruction:\n{instruction}"
        
        result_json = self._call_llm([{"role": "user", "content": prompt}], system_prompt, json_mode=True)
        
        if not result_json:
            print("‚ùå LLM failed to generate valid response")
            return None
            
        modified_code = result_json.get("modified_code")
        
        # Ensure return type is string
        if isinstance(modified_code, list):
            print("‚ö†Ô∏è Detected LLM returned list, attempting to convert to string")
            modified_code = '\n'.join(str(item) for item in modified_code)
        elif not isinstance(modified_code, str):
            print(f"‚ùå LLM returned invalid type: {type(modified_code)}")
            return None
            
        # Add safety check: prevent LLM from returning entire document
        original_length = len(original_snippet)
        modified_length = len(modified_code)
        
        # If modified code length exceeds 3x original code, may be abnormal
        if modified_length > original_length * 3:
            print(f"‚ö†Ô∏è Warning: Modified code length abnormal ({modified_length} vs {original_length})")
            print("This may indicate LLM returned excessive code.")
            
            # Check if contains document header identifiers
            if "\\documentclass" in modified_code and "\\begin{document}" in modified_code:
                print("‚ùå Detected LLM incorrectly returned complete document, rejecting this modification")
                return None
        
        return modified_code
    
    def _find_and_replace_frame(self, original_snippet, modified_snippet):
        """
        Âú®ÊñáÊ°£‰∏≠Êü•ÊâæÂπ∂ÊõøÊç¢‰ª£Á†ÅÁâáÊÆµÔºà‰∏ç‰æùËµñÈ°µÁ†ÅÊ†áËÆ∞Ôºâ
        
        Args:
            original_snippet: ÂéüÂßã‰ª£Á†ÅÁâáÊÆµ
            modified_snippet: ‰øÆÊîπÂêéÁöÑ‰ª£Á†ÅÁâáÊÆµ
            
        Returns:
            tuple: (success: bool, updated_snippet: str)
        """
        try:
            # Áõ¥Êé•Âú®ÊñáÊ°£‰∏≠Êü•ÊâæÂéüÂßãÁâáÊÆµ
            if original_snippet in self.document_content:
                # ÊâßË°åÊõøÊç¢
                old_length = len(self.document_content)
                self.document_content = self.document_content.replace(original_snippet, modified_snippet, 1)
                new_length = len(self.document_content)
                
                if old_length != new_length or original_snippet != modified_snippet:
                    print(f"‚úì ‰øÆÊîπÂ∑≤ÊàêÂäüÂ∫îÁî®Âà∞ÂÜÖÂ≠ò‰∏≠ÁöÑÊñáÊ°£")
                    print(f"   ÊñáÊ°£ÈïøÂ∫¶ÂèòÂåñ: {old_length} -> {new_length} ({new_length - old_length:+d})")
                    
                    # Â¶ÇÊûúÊñáÊ°£ÁªìÊûÑÂèëÁîüÊòæËëóÂèòÂåñÔºåÈáçÊñ∞ÁîüÊàêÂú∞Âõæ
                    if abs(new_length - old_length) > 50:  # ÈòàÂÄºÂèØË∞ÉÊï¥
                        print("üîÑ Ê£ÄÊµãÂà∞ÊñáÊ°£ÁªìÊûÑÂèòÂåñÔºåÈáçÊñ∞ÁîüÊàêÊñáÊ°£Âú∞Âõæ...")
                        self.document_map = self._build_document_map()
                    
                    return True, modified_snippet
                else:
                    print("‚úì ‰ª£Á†ÅÂÜÖÂÆπÊó†ÂèòÂåñÔºåË∑≥ËøáÊõøÊç¢„ÄÇ")
                    return True, modified_snippet
            else:
                print("‚ùå Âú®ÊñáÊ°£‰∏≠Êú™ÊâæÂà∞ÂéüÂßã‰ª£Á†ÅÁâáÊÆµ")
                print("üí° ËøôÂèØËÉΩÊòØÁî±‰∫éÊñáÊ°£Âú®‰πãÂâçÁöÑ‰øÆÊîπ‰∏≠Â∑≤ÁªèÊîπÂèò")
                return False, original_snippet
                
        except Exception as e:
            print(f"‚ùå ÊõøÊç¢ËøáÁ®ã‰∏≠Âá∫Èîô: {e}")
            return False, original_snippet
    
    def show_diff_and_get_confirmation(self, original_snippet, modified_snippet):
        """
        ÊòæÁ§∫diffÂπ∂ËØ∑Ê±ÇÁî®Êà∑Á°ÆËÆ§
        
        Args:
            original_snippet: ÂéüÂßã‰ª£Á†Å
            modified_snippet: ‰øÆÊîπÂêé‰ª£Á†Å
            
        Returns:
            bool: Áî®Êà∑ÊòØÂê¶Á°ÆËÆ§
        """
        if not isinstance(original_snippet, str) or not isinstance(modified_snippet, str):
            print(f"‚ùå ÂèÇÊï∞Á±ªÂûãÈîôËØØ")
            return False

        diff = unified_diff(
            original_snippet.splitlines(keepends=True),
            modified_snippet.splitlines(keepends=True),
            fromfile='original', tofile='modified',
        )
        
        print("\n--- Âª∫ËÆÆÁöÑ‰øÆÊîπ ---")
        diff_str = "".join(diff)
        if not diff_str.strip():
            print("ü§î Êú™Ê£ÄÊµãÂà∞‰ª£Á†ÅÂèòÂåñ„ÄÇ")
            return False

        for line in diff_str.splitlines():
            if line.startswith('---') or line.startswith('+++'):
                continue
            elif line.startswith('-'):
                print(f"\033[91m{line}\033[0m")  # Á∫¢Ëâ≤
            elif line.startswith('+'):
                print(f"\033[92m{line}\033[0m")  # ÁªøËâ≤  
            elif line.startswith('@@'):
                print(f"\033[94m{line}\033[0m")  # ËìùËâ≤
            else:
                print(line)
        
        print("--------------------")
        
        while True:
            response = input("ÊÇ®Êé•ÂèóËøô‰∏™‰øÆÊîπÂêóÔºü(y/n/c) [y]: ").strip().lower()
            if response in ['', 'y', 'yes']:
                return True
            elif response in ['n', 'no']:
                return False
            elif response in ['c', 'cancel']:
                return False
            else:
                print("ËØ∑ËæìÂÖ• y(ÊòØ)„ÄÅn(Âê¶) Êàñ c(ÂèñÊ∂à)")

    def decide_next_action(self):
        """
        Âü∫‰∫éÂØπËØùÂéÜÂè≤ÂÜ≥ÂÆö‰∏ã‰∏ÄÊ≠•Ë°åÂä®
        
        Returns:
            dict: ÂÜ≥Á≠ñÁªìÊûú
        """
        print("ReAct Agent [ÊÄùËÄÉ‰∏≠]... Ê≠£Âú®ÂàÜÊûêÊÇ®ÁöÑÈúÄÊ±Ç„ÄÇ")
        
        system_prompt = REACT_DECISION_PROMPT
        decision_json = self._call_llm(self.conversation_history, system_prompt, json_mode=True)
        return decision_json

    def _compile_to_pdf(self):
        """
        ÁºñËØëLaTeXÊñá‰ª∂ÁîüÊàêPDF
        
        Returns:
            str: PDFÊñá‰ª∂Ë∑ØÂæÑÔºåÊàñNoneÔºàÂ¶ÇÊûúÂ§±Ë¥•Ôºâ
        """
        tex_path = self.tex_file_path
        output_dir = os.path.dirname(tex_path)
        base_name = os.path.basename(tex_path)
        
        # Ëé∑ÂèñÈ°πÁõÆÊ†πÁõÆÂΩïÔºàpaper-to-beamerÁõÆÂΩïÔºâ
        project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
        
        # ‰ΩøÁî®Áõ∏ÂØπ‰∫éÈ°πÁõÆÊ†πÁõÆÂΩïÁöÑË∑ØÂæÑÔºåËøôÊõ¥ÂÅ•Â£Æ
        relative_tex_path = os.path.relpath(tex_path, project_root)
        relative_output_dir = os.path.relpath(output_dir, project_root)
        
        print("\n--- Ê≠£Âú®ÁºñËØëPDFÔºåËØ∑Á®çÂÄô ---")
        print(f"   Â∑•‰ΩúÁõÆÂΩï: {project_root}")
        print(f"   ÁºñËØëÊñá‰ª∂: {relative_tex_path}")
        print(f"   ËæìÂá∫ÁõÆÂΩï: {relative_output_dir}")
        
        for i in range(2):
            print(f"ÁºñËØëÁ¨¨ {i+1}/2 Ê¨°...")
            try:
                # Âú®È°πÁõÆÊ†πÁõÆÂΩïËøêË°åÔºåÂπ∂‰ΩøÁî®Áõ∏ÂØπË∑ØÂæÑ
                process = subprocess.run(
                    ["xelatex", "-shell-escape", "-interaction=nonstopmode", f"-output-directory={relative_output_dir}", relative_tex_path],
                    cwd=project_root, capture_output=True, text=True, check=True
                )
                print(f"‚úì Á¨¨ {i+1} Ê¨°ÁºñËØëÊàêÂäü")
            except subprocess.CalledProcessError as e:
                print(f"‚ùå Á¨¨ {i+1} Ê¨°ÁºñËØëÂ§±Ë¥•")
                print("ÈîôËØØ‰ø°ÊÅØ:")
                print(e.stdout[-1000:] if e.stdout else "Êó†Ê†áÂáÜËæìÂá∫")
                print(e.stderr[-1000:] if e.stderr else "Êó†ÈîôËØØËæìÂá∫")
                return None
            except FileNotFoundError:
                print("‚ùå Êâæ‰∏çÂà∞ xelatex ÂëΩ‰ª§„ÄÇËØ∑Á°Æ‰øùÂ∑≤ÂÆâË£Ö LaTeX ÁéØÂ¢É„ÄÇ")
                return None
        
        pdf_path = os.path.join(output_dir, os.path.splitext(base_name)[0] + '.pdf')
        if os.path.exists(pdf_path):
            print(f"‚úÖ ÁºñËØëÊàêÂäüÔºÅPDFÂ∑≤ÁîüÊàê: {pdf_path}")
            return pdf_path
        else:
            print("‚ùå ÁºñËØëÂÆåÊàê‰ΩÜÊú™ÊâæÂà∞PDFÊñá‰ª∂„ÄÇ")
            return None

    def run_interactive_session(self):
        """
        ËøêË°å‰∫§‰∫íÂºèÁºñËæë‰ºöËØù - Êñ∞ÁâàÊú¨ÂÆûÁé∞
        """
        print("=== Interactive LaTeX Editor (ReAct Mode) ===")
        print("Describe your modifications in natural language. You can:")
        print("‚Ä¢ Modify existing slide content")
        if self.source_content:
            print("‚Ä¢ Add new slides or expand content based on the original paper")
        print("‚Ä¢ Type 'save' to save changes and exit")
        print("‚Ä¢ Type 'quit' to exit without saving")
        print("üîÑ After each modification, PDF will be automatically compiled for preview")
        print()
        
        while True:
            try:
                user_input = input("üîß Enter your request > ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'ÈÄÄÂá∫', 'q']:
                    print("Goodbye!")
                    break
                elif user_input.lower() in ['save', '‰øùÂ≠ò', 's']:
                    print("üîÑ Saving changes...")
                    self._save_document_if_requested()
                    break
                elif not user_input: 
                    continue

                self.conversation_history.append({"role": "user", "content": user_input})
                
                decision = self.decide_next_action()
                
                if not decision or "action" not in decision:
                    print("‚ùå Cannot understand your request, please try a different way.")
                    self.conversation_history.append({"role": "assistant", "content": "Sorry, I cannot understand your request."})
                    continue

                if decision["action"] == "clarify":
                    question = decision.get("question", "Please provide more details.")
                    print(f"Agent: {question}")
                    self.conversation_history.append({"role": "assistant", "content": question})
                    continue
                
                if decision["action"] == "plan":
                    plan = decision.get("plan")
                    if not plan:
                        print("‚ùå Plan generation failed.")
                        continue
                    
                    print("\n‚úì Execution plan generated:")
                    for step in plan:
                        print(f"  - Step {step['step']} ({step['action']}): {step['description']}")
                    print()

                    # ÊâßË°åËÆ°Âàí
                    print("üîÑ Executing plan...")
                    self._execute_plan(plan)
                    print("‚úÖ Plan execution completed")
                    
                    # Ëá™Âä®ÁºñËØëPDFËÆ©Áî®Êà∑ÁúãÂà∞ÊïàÊûú
                    print("üîÑ Compiling PDF to show changes...")
                    pdf_path = self._compile_to_pdf()
                    if pdf_path:
                        print(f"‚úÖ PDF updated: {pdf_path}")
                        print("üìÑ You can now review the changes in the PDF")
                    else:
                        print("‚ö†Ô∏è PDF compilation failed, but changes are saved in memory")
                    
                    # ËØ¢ÈóÆÁî®Êà∑ÊòØÂê¶ÁªßÁª≠‰øÆÊîπ
                    print("\n" + "="*60)
                    print("üéØ Changes applied! You can:")
                    print("   ‚Ä¢ Enter new modification requests")
                    print("   ‚Ä¢ Type 'save' to save changes and exit")
                    print("   ‚Ä¢ Type 'quit' to exit without saving")
                    print("="*60)
                    
                    # ÈáçÁΩÆÂØπËØùÂéÜÂè≤ÔºåÂºÄÂßãÊñ∞ÁöÑ‰ªªÂä°
                    self.conversation_history = []

            except KeyboardInterrupt:
                print("\nGoodbye!")
                break
            except Exception as e:
                print(f"‚ùå Critical error occurred: {e}")
                import traceback
                traceback.print_exc()
                print("üîß Please check the error details above and try again.")

    def _execute_plan(self, plan):
        """
        ÊâßË°åËÆ°Âàí - Êñ∞ÁâàÊú¨ÂÆûÁé∞
        
        Args:
            plan: ÊâßË°åËÆ°ÂàíÂàóË°®
        """
        locate_results = None
        
        for step in plan:
            print(f"--- Ê≠£Âú®ÊâßË°åÊ≠•È™§ {step['step']}/{len(plan)} ---")
            
            if step['action'] == 'locate':
                # ‰ΩøÁî®Êñ∞ÁöÑÊô∫ËÉΩÂÆö‰ΩçÁ≥ªÁªü
                locate_results = self.locate_code_snippet(step['description'])
                if not locate_results or not locate_results.get("snippets"):
                    print("‚ùå ÂÆö‰ΩçÂ§±Ë¥•Ôºå‰∏≠Ê≠¢ËÆ°Âàí„ÄÇ")
                    break
                print("‚úì ÂÆö‰ΩçÊàêÂäüÔºÅ")
                
            elif step['action'] == 'modify':
                if locate_results and locate_results.get("snippets"):
                    # Âü∫‰∫éÂÆö‰ΩçÁªìÊûúËøõË°å‰øÆÊîπ - ‰∏ÄÊ¨°Â§ÑÁêÜ‰∏Ä‰∏™ÁâáÊÆµ
                    self._execute_modifications(locate_results, step['description'])
                else:
                    print("‚ùå ‰øÆÊîπÂ§±Ë¥•ÔºåÂâç‰∏ÄÊ≠•ÁöÑÂÆö‰ΩçÊú™ÊàêÂäü„ÄÇ")
                    break
                    
            elif step['action'] == 'insert':
                if locate_results and locate_results.get("snippets"):
                    # ÊâßË°åÊèíÂÖ•Êìç‰Ωú
                    self._execute_insert(locate_results, step['description'])
                else:
                    print("‚ùå ÊèíÂÖ•Â§±Ë¥•ÔºåÂâç‰∏ÄÊ≠•ÁöÑÂÆö‰ΩçÊú™ÊàêÂäü„ÄÇ")
                    break
                    
            elif step['action'] == 'delete':
                if locate_results and locate_results.get("snippets"):
                    # ÊâßË°åÂà†Èô§Êìç‰Ωú
                    self._execute_delete(locate_results, step['description'])
                else:
                    print("‚ùå Âà†Èô§Â§±Ë¥•ÔºåÂâç‰∏ÄÊ≠•ÁöÑÂÆö‰ΩçÊú™ÊàêÂäü„ÄÇ")
                    break
                    
            elif step['action'] == 'reference_search':
                # ÊâßË°åÂºïÁî®Ê£ÄÁ¥¢Êìç‰Ωú
                search_result = self._execute_reference_search(step['description'])
                if search_result:
                    # Â∞ÜÊ£ÄÁ¥¢ÁªìÊûúÂ≠òÂÇ®Ôºå‰æõÂêéÁª≠Ê≠•È™§‰ΩøÁî®
                    if not hasattr(self, 'reference_search_results'):
                        self.reference_search_results = {}
                    # ÊèêÂèñÊ¶ÇÂøµÂêçÁß∞‰Ωú‰∏∫ÈîÆ
                    concept = self._extract_concept_from_description(step['description'])
                    self.reference_search_results[concept] = search_result
                    print(f"‚úì ÂºïÁî®Ê£ÄÁ¥¢ÂÆåÊàêÔºåÊ¶ÇÂøµ'{concept}'ÁöÑÊâ©Â±ïÂÜÖÂÆπÂ∑≤ÂáÜÂ§áÂ∞±Áª™")
                else:
                    print("‚ùå ÂºïÁî®Ê£ÄÁ¥¢Â§±Ë¥•")
                    break
                    
            else:
                print(f"‚ùå Êú™Áü•ÁöÑÊìç‰ΩúÁ±ªÂûã: {step['action']}")
                break

    def _execute_modifications(self, locate_results, base_instruction):
        """
        ÊâßË°å‰øÆÊîπÊìç‰Ωú
        
        Args:
            locate_results: ÂÆö‰ΩçÁªìÊûú
            base_instruction: Âü∫Á°Ä‰øÆÊîπÊåá‰ª§
        """
        snippets = locate_results["snippets"]
        analysis = locate_results.get("analysis", "")
        
        print(f"   Â∞ÜÂü∫‰∫é {len(snippets)} ‰∏™ÂÆö‰ΩçÁâáÊÆµËøõË°å‰øÆÊîπ")
        if analysis:
            print(f"   ÂàÜÊûêÁªìÊûú: {analysis}")
        
        # ÂØπÊØè‰∏™ÁâáÊÆµÈÄê‰∏Ä‰øÆÊîπ
        for i, snippet_info in enumerate(snippets):
            slide_num = snippet_info.get("slide_number", "Êú™Áü•")
            original_code = snippet_info.get("code", "")
            description = snippet_info.get("description", "")
            
            print(f"\n   ‰øÆÊîπÁâáÊÆµ {i+1}/{len(snippets)} (Á¨¨{slide_num}È°µ):")
            
            # ÊûÑÂª∫ÂåÖÂê´ÂÆåÊï¥‰∏ä‰∏ãÊñáÁöÑ‰øÆÊîπÊåá‰ª§
            contextual_instruction = f"{base_instruction}\n\n‰∏ä‰∏ãÊñáÂàÜÊûê: {analysis}\n\nÈíàÂØπÁ¨¨{slide_num}È°µÁöÑÂÖ∑‰Ωì‰øÆÊîπ: {description}"
            
            modified_snippet = self.generate_modified_code(original_code, contextual_instruction, self.document_content)
            if not modified_snippet:
                print(f"   ‚ùå Á¨¨{slide_num}È°µ‰øÆÊîπÂ§±Ë¥•ÔºåË∑≥Ëøá")
                continue
                
            if self.show_diff_and_get_confirmation(original_code, modified_snippet):
                print(f"\n   --- Ê≠£Âú®‰øÆÊîπÁ¨¨{slide_num}È°µ ---")
                success, _ = self._find_and_replace_frame(original_code, modified_snippet)
                if success:
                    print(f"   ‚úÖ Á¨¨{slide_num}È°µ‰øÆÊîπÊàêÂäü")
                else:
                    print(f"   ‚ùå Á¨¨{slide_num}È°µ‰øÆÊîπÂ§±Ë¥•")
            else:
                print(f"   ‚úó Á¨¨{slide_num}È°µ‰øÆÊîπË¢´ÂèñÊ∂à")

    def _execute_insert(self, locate_results, base_instruction):
        """
        ÊâßË°åÊèíÂÖ•Êìç‰Ωú
        
        Args:
            locate_results: ÂÆö‰ΩçÁªìÊûúÔºàÁî®‰ΩúÊèíÂÖ•ÂèÇËÄÉÁÇπÔºâ
            base_instruction: ÊèíÂÖ•Êåá‰ª§ÊèèËø∞
        """
        snippets = locate_results["snippets"]
        analysis = locate_results.get("analysis", "")
        
        print(f"   Â∞ÜÂú® {len(snippets)} ‰∏™ÂÆö‰ΩçÁâáÊÆµÂêéËøõË°åÊèíÂÖ•")
        if analysis:
            print(f"   ÂàÜÊûêÁªìÊûú: {analysis}")
        
        # ÈÄöÂ∏∏Âè™‰ΩøÁî®Á¨¨‰∏Ä‰∏™ÁâáÊÆµ‰Ωú‰∏∫ÊèíÂÖ•ÂèÇËÄÉÁÇπ
        if not snippets:
            print("   ‚ùå Ê≤°ÊúâÊâæÂà∞ÊèíÂÖ•ÂèÇËÄÉÁÇπ")
            return
            
        reference_snippet = snippets[0]  # ‰ΩøÁî®Á¨¨‰∏Ä‰∏™ÁâáÊÆµ‰Ωú‰∏∫ÂèÇËÄÉ
        slide_num = reference_snippet.get("slide_number", "Êú™Áü•")
        reference_code = reference_snippet.get("code", "")
        
        print(f"\n   Âú®Á¨¨{slide_num}È°µÂêéÊèíÂÖ•Êñ∞ÂÜÖÂÆπ")
        
        # ÂáÜÂ§áÊèíÂÖ•ÂÜÖÂÆπÁöÑÁîüÊàêÊèêÁ§∫ËØç
        insert_prompt = create_content_insertion_prompt(
            base_instruction, analysis, slide_num, reference_code
        )
        
        # Ê£ÄÊü•ÊòØÂê¶ÊúâÂºïÁî®Ê£ÄÁ¥¢ÁªìÊûúÂèØÁî®
        reference_content = None
        if hasattr(self, 'reference_search_results') and self.reference_search_results:
            # Â∞ùËØïÂåπÈÖçÁõ∏ÂÖ≥ÁöÑÊ¶ÇÂøµ
            for concept, result in self.reference_search_results.items():
                if concept.lower() in base_instruction.lower() or any(kw in base_instruction.lower() for kw in concept.lower().split()):
                    reference_content = result
                    break
        
        if reference_content:
            print(f"   ‚ú® Â∞Ü‰ΩøÁî®ÂºïÁî®Ê£ÄÁ¥¢ÁöÑÊâ©Â±ïÂÜÖÂÆπ: '{reference_content['concept']}'")
            insert_prompt += f"""

üéØ ÂºïÁî®Ê£ÄÁ¥¢Êâ©Â±ïÂÜÖÂÆπÔºàÊù•Ëá™‰∏ì‰∏öÊñáÁåÆÔºâ:
Ê¶ÇÂøµ: {reference_content['concept']}
Ë¥®ÈáèËØÑÂàÜ: {reference_content['quality_score']:.2f}

Êâ©Â±ïÂÜÖÂÆπ:
{reference_content['enhanced_content']}

ÂÖ≥ÈîÆË¶ÅÁÇπ:
{chr(10).join(f"- {point}" for point in reference_content.get('key_points', [])[:5])}

Êù•Ê∫êÊñáÁåÆ: {len(reference_content.get('source_papers', []))} ÁØá‰∏ì‰∏öÊñáÁåÆ

ËØ∑‰ºòÂÖà‰ΩøÁî®‰ª•‰∏äÊâ©Â±ïÂÜÖÂÆπÊù•ÁîüÊàê‰∏ì‰∏ö„ÄÅÂáÜÁ°ÆÁöÑÂπªÁÅØÁâá„ÄÇ
"""
        
        if self.source_content:
            insert_prompt += f"\n\nÂéüÂßãPDFÂÜÖÂÆπÔºàÁî®‰∫éÂèÇËÄÉÔºâ:\n```json\n{json.dumps(self.source_content, ensure_ascii=False, indent=2)}\n```"
        
        response = self._call_llm([{"role": "user", "content": insert_prompt}], 
                                 LATEX_EXPERT_SYSTEM_PROMPT, 
                                 json_mode=True)
        
        if not response or not response.get("insert_content"):
            print("   ‚ùå Êó†Ê≥ïÁîüÊàêÊèíÂÖ•ÂÜÖÂÆπ")
            return
            
        insert_content = response["insert_content"]
        
        # ÊòæÁ§∫Ë¶ÅÊèíÂÖ•ÁöÑÂÜÖÂÆπÈ¢ÑËßà
        print(f"\n--- Ë¶ÅÊèíÂÖ•ÁöÑÂÜÖÂÆπÈ¢ÑËßà ---")
        preview = insert_content[:300] + "..." if len(insert_content) > 300 else insert_content
        print(preview)
        print("--- È¢ÑËßàÁªìÊùü ---")
        
        # ËØ∑Ê±ÇÁî®Êà∑Á°ÆËÆ§
        confirm = input(f"\n{USER_CONFIRMATION_PROMPTS['insert_confirmation']}").strip().lower()
        if confirm not in ['', 'y', 'yes']:
            print("   ‚úó Insert operation cancelled")
            return
        
        # ÊâßË°åÊèíÂÖ•ÔºöÂú®ÂèÇËÄÉ‰ª£Á†ÅÁâáÊÆµ‰πãÂêéÊèíÂÖ•Êñ∞ÂÜÖÂÆπ
        insert_position = self.document_content.find(reference_code)
        if insert_position != -1:
            # ÊâæÂà∞ÂèÇËÄÉÁâáÊÆµÁöÑÁªìÊùü‰ΩçÁΩÆ
            end_position = insert_position + len(reference_code)
            
            # ÊèíÂÖ•Êñ∞ÂÜÖÂÆπÔºàÂú®ÂèÇËÄÉÁâáÊÆµÂêéÊ∑ªÂä†Êç¢Ë°åÁ¨¶ÂíåÊñ∞ÂÜÖÂÆπÔºâ
            new_content = (
                self.document_content[:end_position] + 
                "\n\n" + insert_content + 
                self.document_content[end_position:]
            )
            
            old_length = len(self.document_content)
            self.document_content = new_content
            new_length = len(self.document_content)
            
            print(f"   ‚úÖ ÊèíÂÖ•ÊàêÂäüÔºÅÊñáÊ°£ÈïøÂ∫¶ÂèòÂåñ: {old_length} -> {new_length} (+{new_length - old_length})")
            
            # ÈáçÊñ∞ÁîüÊàêÊñáÊ°£Âú∞Âõæ
            print("   üîÑ ÈáçÊñ∞ÁîüÊàêÊñáÊ°£Âú∞Âõæ...")
            self._build_document_map()
        else:
            print("   ‚ùå Êó†Ê≥ïÂú®ÊñáÊ°£‰∏≠ÊâæÂà∞ÊèíÂÖ•ÂèÇËÄÉÁÇπ")

    def _execute_delete(self, locate_results, base_instruction):
        """
        ÊâßË°åÂà†Èô§Êìç‰Ωú
        
        Args:
            locate_results: ÂÆö‰ΩçÁªìÊûúÔºàË¶ÅÂà†Èô§ÁöÑÂÜÖÂÆπÔºâ
            base_instruction: Âà†Èô§Êåá‰ª§ÊèèËø∞
        """
        snippets = locate_results["snippets"]
        analysis = locate_results.get("analysis", "")
        
        print(f"   Â∞ÜÂà†Èô§ {len(snippets)} ‰∏™ÂÆö‰ΩçÁâáÊÆµ")
        if analysis:
            print(f"   ÂàÜÊûêÁªìÊûú: {analysis}")
        
        if not snippets:
            print("   ‚ùå Ê≤°ÊúâÊâæÂà∞Ë¶ÅÂà†Èô§ÁöÑÂÜÖÂÆπ")
            return
        
        # ÊòæÁ§∫Ë¶ÅÂà†Èô§ÁöÑÂÜÖÂÆπ
        print(f"\n--- Ë¶ÅÂà†Èô§ÁöÑÂÜÖÂÆπ ---")
        for i, snippet in enumerate(snippets, 1):
            slide_num = snippet.get("slide_number", "Êú™Áü•")
            code = snippet.get("code", "")
            desc = snippet.get("description", "")
            preview = code[:200] + "..." if len(code) > 200 else code
            print(f"{i}. Á¨¨{slide_num}È°µ: {desc}")
            print(f"   ‰ª£Á†ÅÈ¢ÑËßà: {preview}")
            print()
        print("--- È¢ÑËßàÁªìÊùü ---")
        
        # ËØ∑Ê±ÇÁî®Êà∑Á°ÆËÆ§
        confirm = input(f"\nÊÇ®Á°ÆËÆ§Ë¶ÅÂà†Èô§Ëøô{len(snippets)}‰∏™ÁâáÊÆµÂêóÔºü(y/n) [y]: ").strip().lower()
        if confirm not in ['', 'y', 'yes']:
            print("   ‚úó Âà†Èô§Êìç‰ΩúË¢´ÂèñÊ∂à")
            return
        
        # ÊâßË°åÂà†Èô§ÔºöÈÄê‰∏™Âà†Èô§ÁâáÊÆµÔºà‰ªéÂêéÂæÄÂâçÂà†Èô§ÔºåÈÅøÂÖç‰ΩçÁΩÆÂèòÂåñÈóÆÈ¢òÔºâ
        deleted_count = 0
        snippets_sorted = sorted(snippets, key=lambda x: self.document_content.find(x.get("code", "")), reverse=True)
        
        for snippet in snippets_sorted:
            code = snippet.get("code", "")
            slide_num = snippet.get("slide_number", "Êú™Áü•")
            
            if code in self.document_content:
                old_length = len(self.document_content)
                self.document_content = self.document_content.replace(code, "", 1)  # Âè™Âà†Èô§Á¨¨‰∏Ä‰∏™ÂåπÈÖç
                new_length = len(self.document_content)
                
                if new_length < old_length:
                    deleted_count += 1
                    print(f"   ‚úÖ Â∑≤Âà†Èô§Á¨¨{slide_num}È°µ (ÂáèÂ∞ë{old_length - new_length}Â≠óÁ¨¶)")
                else:
                    print(f"   ‚ö†Ô∏è Á¨¨{slide_num}È°µÊú™ÂèëÁîüÂèòÂåñ")
            else:
                print(f"   ‚ùå Êó†Ê≥ïÊâæÂà∞Á¨¨{slide_num}È°µÁöÑ‰ª£Á†ÅËøõË°åÂà†Èô§")
        
        if deleted_count > 0:
            print(f"   ‚úÖ Âà†Èô§ÂÆåÊàêÔºÅÊàêÂäüÂà†Èô§{deleted_count}/{len(snippets)}‰∏™ÁâáÊÆµ")
            
            # ÈáçÊñ∞ÁîüÊàêÊñáÊ°£Âú∞Âõæ
            print("   üîÑ ÈáçÊñ∞ÁîüÊàêÊñáÊ°£Âú∞Âõæ...")
            self._build_document_map()
        else:
            print("   ‚ùå Ê≤°Êúâ‰ªª‰ΩïÂÜÖÂÆπË¢´Âà†Èô§")

    def _save_document_if_requested(self):
        """
        Ask user whether to save document
        """
        print("\n" + "="*60)
        print("üéâ All modifications completed successfully!")
        print("üìÑ Ready to save changes to file...")
        save_confirm = input("\nSave changes to file? (y/n) [y]: ").strip().lower()
        if save_confirm == '' or save_confirm == 'y':
            # ÁîüÊàêÊñ∞ÁöÑÊñá‰ª∂ÂêçÔºåÈÅøÂÖçË¶ÜÁõñÂéüÊñá‰ª∂
            base_dir = os.path.dirname(self.tex_file_path)
            base_name = os.path.splitext(os.path.basename(self.tex_file_path))[0]
            revised_path = os.path.join(base_dir, f"{base_name}_revised.tex")
            
            try:
                with open(revised_path, 'w', encoding='utf-8') as f:
                    f.write(self.document_content)
                print(f"‚úì File saved: {revised_path}")
                
                # Êõ¥Êñ∞ÂΩìÂâçË∑ØÂæÑ‰∏∫Êñ∞Êñá‰ª∂Ë∑ØÂæÑÔºå‰æø‰∫éÂêéÁª≠PDFÁºñËØë
                self.tex_file_path = revised_path
                
                pdf_path = self._compile_to_pdf()
                if pdf_path:
                    open_pdf = input("Open PDF automatically? (y/n) [y]: ").strip().lower()
                    if open_pdf in ['y', '']:
                        try:
                            webbrowser.open(f'file://{os.path.abspath(pdf_path)}')
                        except Exception as e:
                            print(f"Cannot auto-open PDF, please open manually: {pdf_path}")
            except Exception as e:
                print(f"‚ùå Error saving file: {str(e)}")
                print("Trying to save to original location...")
                try:
                    with open(self.tex_file_path, 'w', encoding='utf-8') as f:
                        f.write(self.document_content)
                    print(f"‚úì File saved: {self.tex_file_path}")
                except Exception as e2:
                    print(f"‚ùå Still cannot save: {str(e2)}")
        else:
            print("‚úó File not saved.")
    
    def modify_content(self, description):
        """
        ‰øÆÊîπÂÜÖÂÆπÁöÑÁÆÄÂåñÁâàÊú¨ - ÈÄÇÁî®‰∫éÁõ¥Êé•Ë∞ÉÁî®
        
        Args:
            description: ‰øÆÊîπÊèèËø∞
            
        Returns:
            tuple: (success: bool, message: str)
        """
        try:
            print(f"\nüîÑ ÂºÄÂßã‰øÆÊîπÂÜÖÂÆπ: {description}")
            
            # Ê≠•È™§1: Êô∫ËÉΩÂÆö‰ΩçÈúÄË¶Å‰øÆÊîπÁöÑ‰ΩçÁΩÆ
            location_result = self.locate_code_snippet(description)
            if not location_result or not location_result.get('snippets'):
                print("   ‚ùå Êú™ËÉΩÂÆö‰ΩçÂà∞ÈúÄË¶Å‰øÆÊîπÁöÑÂÜÖÂÆπ")
                return False, f"Êó†Ê≥ïÂÆö‰ΩçË¶Å‰øÆÊîπÁöÑÂÜÖÂÆπ: {description}"
            
            snippets = location_result['snippets']
            analysis = location_result.get('analysis', '')
            
            print(f"   ‚úì ÂÆö‰ΩçÂà∞ {len(snippets)} ‰∏™ÈúÄË¶Å‰øÆÊîπÁöÑ‰ΩçÁΩÆ")
            if analysis:
                print(f"   üìã ÂàÜÊûê: {analysis}")
            
            # Ê≠•È™§2: ‰∏∫ÊØè‰∏™ÁâáÊÆµÁîüÊàê‰øÆÊîπÊñπÊ°àÂπ∂Â∫îÁî®
            success_count = 0
            failed_modifications = []
            
            for i, snippet in enumerate(snippets, 1):
                print(f"\n   Â§ÑÁêÜÁâáÊÆµ {i}/{len(snippets)}: {snippet.get('description', 'N/A')}")
                
                # ÁîüÊàê‰øÆÊîπÂêéÁöÑ‰ª£Á†Å
                modified_code = self.generate_modified_code(
                    snippet['code'], 
                    description, 
                    self.document_content
                )
                
                if not modified_code:
                    failed_modifications.append(f"ÁâáÊÆµ{i}: Êó†Ê≥ïÁîüÊàê‰øÆÊîπÊñπÊ°à")
                    continue
                
                # Â∫îÁî®‰øÆÊîπ
                if snippet['code'] in self.document_content:
                    # ÊõøÊç¢ÂéüÂßã‰ª£Á†Å
                    self.document_content = self.document_content.replace(
                        snippet['code'], 
                        modified_code, 
                        1  # Âè™ÊõøÊç¢Á¨¨‰∏Ä‰∏™ÂåπÈÖçÈ°π
                    )
                    success_count += 1
                    print(f"   ‚úÖ ÁâáÊÆµ{i}‰øÆÊîπÊàêÂäü")
                else:
                    failed_modifications.append(f"ÁâáÊÆµ{i}: Âú®ÊñáÊ°£‰∏≠Êú™ÊâæÂà∞ÂéüÂßã‰ª£Á†Å")
                    print(f"   ‚ùå ÁâáÊÆµ{i}: Âú®ÊñáÊ°£‰∏≠Êú™ÊâæÂà∞ÂéüÂßã‰ª£Á†Å")
            
            # Ê≠•È™§3: Â§ÑÁêÜÁªìÊûú
            if success_count > 0:
                # ÈáçÊñ∞ÁîüÊàêÊñáÊ°£Âú∞Âõæ‰ª•ÂèçÊò†Êõ¥Êîπ
                print("\n   üîÑ ÈáçÊñ∞ÁîüÊàêÊñáÊ°£Âú∞Âõæ...")
                self._build_document_map()
                
                result_msg = f"ÊàêÂäü‰øÆÊîπ‰∫Ü {success_count}/{len(snippets)} ‰∏™‰ΩçÁΩÆ"
                if failed_modifications:
                    result_msg += f"ÔºåÂ§±Ë¥•: {'; '.join(failed_modifications)}"
                
                print(f"\n‚úÖ {result_msg}")
                return True, result_msg
            else:
                error_msg = f"ÊâÄÊúâ‰øÆÊîπÈÉΩÂ§±Ë¥•‰∫Ü: {'; '.join(failed_modifications)}"
                print(f"\n‚ùå {error_msg}")
                return False, error_msg
            
        except Exception as e:
            error_msg = f"‰øÆÊîπÂÜÖÂÆπÊó∂Âá∫Èîô: {e}"
            print(f"\n‚ùå {error_msg}")
            return False, error_msg
    
    def interactive_session(self):
        """
        ÂêØÂä®‰∫§‰∫íÂºèÁºñËæë‰ºöËØù - ÁÆÄÂåñÁâàÊú¨
        """
        print(f"\nüéØ ÂêØÂä®‰∫§‰∫íÂºèLaTeXÁºñËæëÂô®")
        print(f"üìÑ ÂΩìÂâçÊñáÊ°£: {os.path.basename(self.tex_file_path)}")
        print(f"üìä ÊñáÊ°£Áä∂ÊÄÅ: {self.document_map['total_slides']}È°µÂπªÁÅØÁâá" if self.document_map else "ÊñáÊ°£Âú∞Âõæ‰∏çÂèØÁî®")
        print("\nüí° ‰ΩøÁî®ËØ¥Êòé:")
        print("  - ËæìÂÖ•‰øÆÊîπÈúÄÊ±ÇÔºåÂ¶ÇÔºö'‰øÆÊîπÁ¨¨3È°µÁöÑÊ†áÈ¢ò'„ÄÅ'Ë∞ÉÊï¥ÂõæÁâáÂ§ßÂ∞è'")
        print("  - ËæìÂÖ• 'quit' Êàñ 'exit' ÈÄÄÂá∫")
        print("  - ËæìÂÖ• 'save' ‰øùÂ≠òÂΩìÂâç‰øÆÊîπ")
        print("  - ËæìÂÖ• 'status' Êü•ÁúãÊñáÊ°£Áä∂ÊÄÅ")
        print("\n" + "="*60)
        
        while True:
            try:
                user_input = input("\nüîß ËØ∑ËæìÂÖ•‰øÆÊîπÈúÄÊ±Ç > ").strip()
                
                if not user_input:
                    continue
                
                # Â§ÑÁêÜÁâπÊÆäÂëΩ‰ª§
                if user_input.lower() in ['quit', 'exit', 'q']:
                    print("\nüëã ÈÄÄÂá∫ÁºñËæëÂô®")
                    self._save_document_if_requested()
                    break
                
                elif user_input.lower() == 'save':
                    self._save_document_if_requested()
                    continue
                
                elif user_input.lower() == 'status':
                    self._show_document_status()
                    continue
                
                # ÊâßË°å‰øÆÊîπ
                success, message = self.modify_content(user_input)
                
                if success:
                    print(f"‚úÖ {message}")
                else:
                    print(f"‚ùå {message}")
                    
            except KeyboardInterrupt:
                print("\n\nüëã Áî®Êà∑‰∏≠Êñ≠ÔºåÈÄÄÂá∫ÁºñËæëÂô®")
                self._save_document_if_requested()
                break
            except Exception as e:
                print(f"‚ùå Â§ÑÁêÜËæìÂÖ•Êó∂Âá∫Èîô: {e}")
                continue
    
    def _show_document_status(self):
        """ÊòæÁ§∫ÊñáÊ°£Áä∂ÊÄÅ‰ø°ÊÅØ"""
        print("\nüìä ÊñáÊ°£Áä∂ÊÄÅ:")
        print(f"   Êñá‰ª∂: {self.tex_file_path}")
        print(f"   Â§ßÂ∞è: {len(self.document_content)} Â≠óÁ¨¶")
        
        if self.document_map:
            print(f"   ÂπªÁÅØÁâáÊï∞Èáè: {self.document_map['total_slides']} È°µ")
            
            # ÁªüËÆ°ÁâπÊÆäÂÜÖÂÆπ
            images_count = sum(1 for slide in self.document_map['slides'] if slide.get('has_image'))
            tables_count = sum(1 for slide in self.document_map['slides'] if slide.get('has_table'))
            
            if images_count > 0:
                print(f"   Âê´ÂõæÁâáÈ°µÈù¢: {images_count} È°µ")
            if tables_count > 0:
                print(f"   Âê´Ë°®Ê†ºÈ°µÈù¢: {tables_count} È°µ")
                
            # ÊòæÁ§∫Á´†ËäÇ‰ø°ÊÅØ
            sections = set()
            for slide in self.document_map['slides']:
                if slide.get('section'):
                    sections.add(slide['section'])
            
            if sections:
                print(f"   Á´†ËäÇ: {', '.join(sorted(sections))}")
        else:
            print("   ‚ö†Ô∏è ÊñáÊ°£Âú∞Âõæ‰∏çÂèØÁî®")
        
        if hasattr(self, 'source_content') and self.source_content:
            print(f"   ÂéüÂßãPDFÂÜÖÂÆπ: ÂèØÁî®")
        else:
            print(f"   ÂéüÂßãPDFÂÜÖÂÆπ: ‰∏çÂèØÁî®")
        
        if hasattr(self, 'reference_agent') and self.reference_agent:
            print(f"   ÂºïÁî®Ê£ÄÁ¥¢Agent: ÂèØÁî®")
        else:
            print(f"   ÂºïÁî®Ê£ÄÁ¥¢Agent: ‰∏çÂèØÁî®")

    def _execute_reference_search(self, description: str) -> dict:
        """
        ÊâßË°åÂºïÁî®Ê£ÄÁ¥¢Êìç‰Ωú
        
        Args:
            description: Ê£ÄÁ¥¢ÊèèËø∞ÔºåÂåÖÂê´ÁõÆÊ†áÊ¶ÇÂøµ
            
        Returns:
            dict: Ê£ÄÁ¥¢ÁªìÊûúÔºåÂåÖÂê´Êâ©Â±ïÂÜÖÂÆπ
        """
        if not self.reference_agent:
            print("‚ùå ÂºïÁî®Ê£ÄÁ¥¢AgentÊú™ÂàùÂßãÂåñÔºåÂ∞Ü‰ΩøÁî®Âü∫Á°ÄÂÜÖÂÆπÊâ©Â±ï")
            return self._fallback_content_expansion(description)
        
        if not self.workflow_state:
            print("‚ùå Â∑•‰ΩúÊµÅÁä∂ÊÄÅ‰∏çÂèØÁî®ÔºåÊó†Ê≥ïËøõË°åÂºïÁî®Ê£ÄÁ¥¢")
            return self._fallback_content_expansion(description)
        
        # ‰ªéÊèèËø∞‰∏≠ÊèêÂèñÊ¶ÇÂøµÂêçÁß∞
        concept = self._extract_concept_from_description(description)
        
        print(f"üîç Ê≠£Âú®Ê£ÄÁ¥¢Ê¶ÇÂøµ: '{concept}'")
        print("   - ÂàÜÊûêÂéüËÆ∫ÊñáÂºïÁî®...")
        
        try:
            # ÂáÜÂ§áÂºïÁî®Ê£ÄÁ¥¢‰∏ä‰∏ãÊñá
            search_context = self.workflow_state.get_reference_search_context(concept)
            
            # Ê∑ªÂä†ÂΩìÂâçÂØπËØù‰∏ä‰∏ãÊñá
            conversation_context = "\n".join([
                f"{msg['role']}: {msg['content']}" 
                for msg in self.conversation_history[-3:]  # ÊúÄËøë3ËΩÆÂØπËØù
            ])
            
            # ÊâßË°åÂºïÁî®Ê£ÄÁ¥¢
            result = self.reference_agent.enhance_content_with_references(
                original_paper_path=search_context["original_paper_path"],
                target_concept=concept,
                context=conversation_context,
                max_references=2,  # ÈôêÂà∂ÂºïÁî®Êï∞Èáè‰ª•ÊèêÈ´òÊïàÁéá
                output_dir=search_context["output_dir"]
            )
            
            if result['success']:
                print(f"‚úÖ Ê£ÄÁ¥¢ÊàêÂäü! Ë¥®ÈáèËØÑÂàÜ: {result['content_quality_score']:.2f}")
                print(f"   ÊâæÂà∞ {len(result.get('source_papers', []))} ÁØáÁõ∏ÂÖ≥ÊñáÁåÆ")
                
                # ÁÆÄÂåñËøîÂõûÁªìÊûú
                return {
                    'concept': concept,
                    'enhanced_content': result['enhanced_content'],
                    'key_points': result.get('key_points', []),
                    'source_papers': result.get('source_papers', []),
                    'quality_score': result['content_quality_score']
                }
            else:
                print(f"‚ùå Ê£ÄÁ¥¢Â§±Ë¥•: {result.get('error', 'Êú™Áü•ÈîôËØØ')}")
                print("‚ö†Ô∏è Â∞Ü‰ΩøÁî®Âü∫Á°ÄÂÜÖÂÆπÊâ©Â±ï‰Ωú‰∏∫Â§áÈÄâÊñπÊ°à")
                return self._fallback_content_expansion(description)
                
        except Exception as e:
            print(f"‚ùå ÂºïÁî®Ê£ÄÁ¥¢ËøáÁ®ã‰∏≠Âá∫Èîô: {e}")
            print("‚ö†Ô∏è Â∞Ü‰ΩøÁî®Âü∫Á°ÄÂÜÖÂÆπÊâ©Â±ï‰Ωú‰∏∫Â§áÈÄâÊñπÊ°à")
            return self._fallback_content_expansion(description)
    
    def _extract_concept_from_description(self, description: str) -> str:
        """
        ‰ªéÊèèËø∞‰∏≠ÊèêÂèñÊ¶ÇÂøµÂêçÁß∞
        
        Args:
            description: ÊèèËø∞ÊñáÊú¨
            
        Returns:
            str: ÊèêÂèñÁöÑÊ¶ÇÂøµÂêçÁß∞
        """
        import re
        
        # Â∞ùËØï‰ªéÂºïÂè∑‰∏≠ÊèêÂèñ
        quote_match = re.search(r"['\"](.*?)['\"]", description)
        if quote_match:
            return quote_match.group(1).strip()
        
        # Â∞ùËØï‰ªé"ÂÖ≥‰∫éX"Ê®°Âºè‰∏≠ÊèêÂèñ
        about_match = re.search(r"ÂÖ≥‰∫é['\"]?(.*?)['\"]?ÁöÑ", description)
        if about_match:
            return about_match.group(1).strip()
        
        # Â∞ùËØï‰ªéÂ∏∏ËßÅÊäÄÊúØËØçÊ±á‰∏≠ÂåπÈÖç
        tech_terms = ['attention', 'transformer', 'neural', 'learning', 'model', 'network', 'algorithm']
        for term in tech_terms:
            if term in description.lower():
                # ÊèêÂèñÂåÖÂê´ËØ•ËØçÊ±áÁöÑÁü≠ËØ≠
                words = description.split()
                for i, word in enumerate(words):
                    if term in word.lower():
                        # ÂèñÂâçÂêéÂêÑ‰∏Ä‰∏™ËØç‰Ωú‰∏∫Ê¶ÇÂøµ
                        start = max(0, i-1)
                        end = min(len(words), i+2)
                        return ' '.join(words[start:end]).strip()
        
        # Â¶ÇÊûúÈÉΩÊ≤°ÊâæÂà∞ÔºåËøîÂõûÊèèËø∞ÁöÑÂÖ≥ÈîÆËØç
        words = description.split()
        # ËøáÊª§ÊéâÂ∏∏ËßÅÁöÑÂä®ËØçÂíå‰ªãËØç
        stop_words = ['Ëé∑Âèñ', 'Ê£ÄÁ¥¢', 'ÈÄöËøá', 'ÂÖ≥‰∫é', 'ÁöÑ', 'ËøõË°å', '‰ΩøÁî®', 'ÂÆûÁé∞']
        key_words = [w for w in words if w not in stop_words and len(w) > 1]
        
        if key_words:
            return ' '.join(key_words[:2])  # ÂèñÂâç‰∏§‰∏™ÂÖ≥ÈîÆËØç
        
        return "unknown_concept"
    
    def _fallback_content_expansion(self, description: str) -> dict:
        """
        Âü∫Á°ÄÂÜÖÂÆπÊâ©Â±ïÊñπÊ°àÔºàÂΩìÂºïÁî®Ê£ÄÁ¥¢Â§±Ë¥•Êó∂‰ΩøÁî®Ôºâ
        
        Args:
            description: Êâ©Â±ïÊèèËø∞
            
        Returns:
            dict: Âü∫Á°ÄÊâ©Â±ïÂÜÖÂÆπ
        """
        concept = self._extract_concept_from_description(description)
        print(f"üîÑ ‰ΩøÁî®Âü∫Á°ÄÂÜÖÂÆπÊâ©Â±ïÁîüÊàê'{concept}'ÁöÑËß£Èáä")
        
        try:
            # Â¶ÇÊûúÊúâÂéüÂßãPDFÂÜÖÂÆπÔºå‰ªé‰∏≠ÊèêÂèñÁõ∏ÂÖ≥‰ø°ÊÅØ
            if hasattr(self, 'source_content') and self.source_content:
                relevant_content = self._extract_relevant_content_from_source(concept, self.source_content)
            else:
                relevant_content = ""
            
            # ÁîüÊàêÂü∫Á°ÄÊâ©Â±ïÂÜÖÂÆπ
            expanded_content = self._generate_basic_explanation(concept, relevant_content)
            
            return {
                'concept': concept,
                'enhanced_content': expanded_content,
                'key_points': self._extract_basic_key_points(expanded_content),
                'source_papers': [{'title': 'Original Paper', 'authors': ['Original Authors']}],
                'quality_score': 0.6,  # Âü∫Á°ÄÊâ©Â±ïË¥®ÈáèÂàÜ
                'method': 'fallback_expansion'
            }
            
        except Exception as e:
            print(f"‚ö†Ô∏è Âü∫Á°ÄÂÜÖÂÆπÊâ©Â±ï‰πüÂ§±Ë¥•‰∫Ü: {e}")
            return {
                'concept': concept,
                'enhanced_content': f"{concept}ÊòØ‰∏Ä‰∏™ÈáçË¶ÅÁöÑÊäÄÊúØÊ¶ÇÂøµÔºåÂú®Êú¨Á†îÁ©∂‰∏≠Ëµ∑Âà∞ÂÖ≥ÈîÆ‰ΩúÁî®„ÄÇ",
                'key_points': [f"{concept}ÁöÑÈáçË¶ÅÊÄß", "Âú®Á†îÁ©∂‰∏≠ÁöÑÂ∫îÁî®"],
                'source_papers': [],
                'quality_score': 0.3,
                'method': 'minimal_fallback'
            }
    
    def _extract_relevant_content_from_source(self, concept: str, source_content: str) -> str:
        """‰ªéÂéüÂßãÂÜÖÂÆπ‰∏≠ÊèêÂèñÁõ∏ÂÖ≥ÊÆµËêΩ"""
        if not source_content or not concept:
            return ""
        
        # Â∞ÜconceptËΩ¨Êç¢‰∏∫ÊêúÁ¥¢ÂÖ≥ÈîÆËØç
        search_terms = [concept.lower()]
        if ' ' in concept:
            search_terms.extend(concept.lower().split())
        
        # ÂàÜÊÆµÊêúÁ¥¢
        paragraphs = source_content.split('\n\n')
        relevant_paragraphs = []
        
        for para in paragraphs:
            para_lower = para.lower()
            if any(term in para_lower for term in search_terms) and len(para.strip()) > 50:
                relevant_paragraphs.append(para.strip())
        
        return '\n\n'.join(relevant_paragraphs[:3])  # ÊúÄÂ§ö3‰∏™Áõ∏ÂÖ≥ÊÆµËêΩ
    
    def _generate_basic_explanation(self, concept: str, relevant_content: str) -> str:
        """ÁîüÊàêÂü∫Á°ÄÊäÄÊúØËß£Èáä"""
        if relevant_content:
            return f"""## {concept.title()}

**ÊäÄÊúØÊ¶ÇËø∞:**
{concept}ÊòØÊú¨Á†îÁ©∂‰∏≠ÈááÁî®ÁöÑÈáçË¶ÅÊäÄÊúØÊñπÊ≥ï„ÄÇ

**Âú®Êú¨Á†îÁ©∂‰∏≠ÁöÑÂ∫îÁî®:**
{relevant_content[:500]}...

**ÊäÄÊúØÁâπÁÇπ:**
‚Ä¢ Âú®Áõ∏ÂÖ≥È¢ÜÂüüÂÖ∑ÊúâÈáçË¶ÅÊÑè‰πâ
‚Ä¢ ËÉΩÂ§üÊúâÊïàËß£ÂÜ≥ÁâπÂÆöÈóÆÈ¢ò
‚Ä¢ ÂÖ∑ÊúâËâØÂ•ΩÁöÑÊÄßËÉΩË°®Áé∞

**Áõ∏ÂÖ≥ËÉåÊôØ:**
ËØ•ÊäÄÊúØÂú®ÂΩìÂâçÁ†îÁ©∂È¢ÜÂüüÂæóÂà∞ÂπøÊ≥õÂ∫îÁî®Ôºå‰∏∫ÈóÆÈ¢òËß£ÂÜ≥Êèê‰æõ‰∫ÜÊúâÊïàÈÄîÂæÑ„ÄÇ
"""
        else:
            return f"""## {concept.title()}

**ÂÆö‰πâ:**
{concept}ÊòØÊú¨Á†îÁ©∂‰∏≠ÁöÑÂÖ≥ÈîÆÊäÄÊúØÊ¶ÇÂøµ„ÄÇ

**ÈáçË¶ÅÊÄß:**
‚Ä¢ Âú®Á†îÁ©∂ÊñπÊ≥ï‰∏≠Ëµ∑Âà∞Ê†∏ÂøÉ‰ΩúÁî®
‚Ä¢ ‰∏∫ÈóÆÈ¢òËß£ÂÜ≥Êèê‰æõÊäÄÊúØÊîØÊíë
‚Ä¢ ÂÖ∑ÊúâÁêÜËÆ∫ÂíåÂÆûË∑µÊÑè‰πâ

**Â∫îÁî®ÁâπÁÇπ:**
ËØ•ÊäÄÊúØÊñπÊ≥ïÂú®Áõ∏ÂÖ≥Á†îÁ©∂‰∏≠Â±ïÁé∞Âá∫ËâØÂ•ΩÁöÑÊÄßËÉΩÔºå‰∏∫Á†îÁ©∂ÁõÆÊ†áÁöÑÂÆûÁé∞Êèê‰æõ‰∫ÜÈáçË¶Å‰øùÈöú„ÄÇ
"""
    
    def _extract_basic_key_points(self, content: str) -> list:
        """‰ªéÂü∫Á°ÄÂÜÖÂÆπ‰∏≠ÊèêÂèñÂÖ≥ÈîÆÁÇπ"""
        key_points = []
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            if line.startswith('‚Ä¢ ') or line.startswith('- '):
                key_points.append(line[2:])
            elif line.startswith('**') and line.endswith(':**'):
                key_points.append(line.strip('*:'))
        
        return key_points[:5]  # ÊúÄÂ§ö5‰∏™ÂÖ≥ÈîÆÁÇπ
